{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv = pd.read_csv('median_income_data.csv')\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how I knew which rows were specifically for Florida\n",
    "\n",
    "# florida = csv.loc[csv['Table with row headers in column A and column headers in rows 5 and 6, and 60 and 61'] == 'Florida']\n",
    "# florida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_csv = csv.T.reset_index(); \n",
    "flipped_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_csv.columns = flipped_csv.iloc[0]\n",
    "flipped_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It was literally faster and easier to type out 34 years worth of numerals than to fight with Pandas to convert and reconvert the array to usable data\n",
    "years = [1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
    "# pd.DataFrame(years)\n",
    "\n",
    "years.reverse()\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we're going to narrow the data set down to states and national averages\n",
    "getting_states_data = flipped_csv.dropna(axis=1)\n",
    "getting_states_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I noticed we have duplicated states, lets get rid of those...\n",
    "narrowed_data = df = getting_states_data.loc[:,~getting_states_data.columns.duplicated()]\n",
    "narrowed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of the first column with the weird name\n",
    "mean_state_data = narrowed_data.drop(columns = 'Table with row headers in column A and column headers in rows 5 and 6, and 60 and 61')\n",
    "mean_state_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to flip the columns again and make the states the index\n",
    "making_missy_elliot_proud = mean_state_data.T \n",
    "making_missy_elliot_proud.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cool, now I need to drop the first column, then every other column, and then use \"years\" as the column headers\n",
    "dropping_first_column = making_missy_elliot_proud.drop(axis=1, columns=0)\n",
    "dropping_first_column\n",
    "\n",
    "# # Saving for now -- Will need to see how many columns need to go\n",
    "# dropping_first_column.to_csv('almost_done_all_states', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We needed to drop it down to 37 columns because we have 37 years of data\n",
    "narrowed_columns = dropping_first_column[dropping_first_column.columns[::2]]\n",
    "narrowed_columns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're almost done here, I should be able to rename the columns using the \"years\" list we created and reversed earlier\n",
    "df2 = narrowed_columns.set_axis([years], axis=1, inplace=False)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.reset_index()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopefully_fixed = df2.rename({0: \"State\"}, axis=1)\n",
    "hopefully_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"sqlite:///average_regional_incomes.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopefully_fixed.to_sql(name='avg_regional_incomes', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('SELECT * FROM avg_regional_incomes', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
